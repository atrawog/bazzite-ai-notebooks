{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a10004e",
   "metadata": {},
   "source": [
    "# Unsloth Vision Training Verification\n",
    "\n",
    "This notebook tests the complete vision model fine-tuning pipeline:\n",
    "- FastVisionModel loading\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training\n",
    "\n",
    "**Important:** This notebook includes a kernel shutdown cell at the end\n",
    "to release all GPU memory after the vision training test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05acbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN loaded: YesðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pixi/.pixi/envs/default/lib/python3.13/site-packages/trl/__init__.py:203: UserWarning: TRL currently supports vLLM versions: 0.10.2, 0.11.0, 0.11.1, 0.11.2. You have version 0.14.0rc1.dev201+gadcf682fc.cu130 installed. We recommend installing a supported version to avoid compatibility issues.\n",
      "  if is_vllm_available():"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!unsloth: 2025.12.10\n",
      "transformers: 5.0.0rc1\n",
      "vLLM: 0.14.0rc1.dev201+gadcf682fc\n",
      "TRL: 0.26.2\n",
      "PyTorch: 2.9.1+cu130\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Force text-based progress instead of HTML widgets\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"false\"\n",
    "print(f\"HF_TOKEN loaded: {'Yes' if os.environ.get('HF_TOKEN') else 'No'}\")\n",
    "\n",
    "# CRITICAL: Import unsloth FIRST for proper TRL patching\n",
    "import unsloth\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "import transformers\n",
    "import vllm\n",
    "import trl\n",
    "import torch\n",
    "\n",
    "print(f\"unsloth: {unsloth.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"vLLM: {vllm.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6629",
   "metadata": {},
   "source": [
    "## Ministral VL (Vision) Training Verification\n",
    "\n",
    "This section tests the complete vision model fine-tuning pipeline:\n",
    "- FastVisionModel loading\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ba143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Vision Pipeline Test (self-contained)\n",
    "# Tests: Model loading, LoRA, Dataset, Training (2 steps), Inference\n",
    "print(\"=== Vision Training Pipeline Test ===\")\n",
    "\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Load model\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Ministral-3-3B-Reasoning-2512\",\n",
    "    load_in_4bit=True,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    ")\n",
    "print(f\"âœ“ FastVisionModel loaded: {type(model).__name__}\")\n",
    "\n",
    "# 2. Apply LoRA\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    random_state=3407,\n",
    ")\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ“ LoRA applied ({trainable:,} trainable params)\")\n",
    "\n",
    "# 3. Load dataset\n",
    "dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train[:5]\")\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "converted_dataset = [convert_to_conversation(s) for s in dataset]\n",
    "print(f\"âœ“ Dataset loaded ({len(converted_dataset)} samples)\")\n",
    "\n",
    "# 4. Train (2 steps)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset=converted_dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        max_steps=2,\n",
    "        warmup_steps=0,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        fp16=not is_bf16_supported(),\n",
    "        bf16=is_bf16_supported(),\n",
    "        output_dir=\"outputs_ministral_vl_test\",\n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        max_seq_length=1024,\n",
    "    ),\n",
    ")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"âœ“ Training completed (loss: {trainer_stats.metrics.get('train_loss', 'N/A'):.4f})\")\n",
    "\n",
    "# 5. Inference test\n",
    "FastVisionModel.for_inference(model)\n",
    "test_image = dataset[0][\"image\"]\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}]}]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(test_image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=64, temperature=1.5, min_p=0.1)\n",
    "print(\"âœ“ Inference test passed\")\n",
    "print(\"âœ“ Vision Training Pipeline test PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a4288",
   "metadata": {},
   "source": [
    "## Test Complete\n",
    "\n",
    "The Vision Training Pipeline test has completed. The kernel will now shut down to release all GPU memory.\n",
    "\n",
    "### What Was Verified\n",
    "- FastVisionModel loading with 4-bit quantization\n",
    "- LoRA adapter application (vision + language layers)\n",
    "- Dataset loading and conversation formatting\n",
    "- SFTTrainer training loop (2 steps)\n",
    "- Post-training inference\n",
    "\n",
    "### Ready for Production\n",
    "If this test passed, your environment is ready for:\n",
    "- `Ministral_3_VL_(3B)_Vision.ipynb` - Full vision fine-tuning tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ea73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down kernel to release GPU memory..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shutdown kernel to release all GPU memory\n",
    "import IPython\n",
    "print(\"Shutting down kernel to release GPU memory...\")\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}