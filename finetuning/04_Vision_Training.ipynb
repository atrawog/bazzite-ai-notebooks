{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a10004e",
   "metadata": {},
   "source": [
    "# Unsloth Vision Training Verification\n",
    "\n",
    "This notebook tests the complete vision model fine-tuning pipeline:\n",
    "- FastVisionModel loading\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training\n",
    "\n",
    "**Important:** This notebook includes a kernel shutdown cell at the end\n",
    "to release all GPU memory after the vision training test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05acbdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN loaded: Yes",
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pixi/.pixi/envs/default/lib/python3.13/site-packages/trl/__init__.py:203: UserWarning: TRL currently supports vLLM versions: 0.10.2, 0.11.0, 0.11.1, 0.11.2. You have version 0.14.0rc1.dev201+gadcf682fc.cu130 installed. We recommend installing a supported version to avoid compatibility issues.\n  if is_vllm_available():"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!",
      "unsloth: 2025.12.10\ntransformers: 5.0.0rc1\nvLLM: 0.14.0rc1.dev201+gadcf682fc\nTRL: 0.26.2\nPyTorch: 2.9.1+cu130\nCUDA: True\nGPU: NVIDIA GeForce RTX 4080 SUPER"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(f\"HF_TOKEN loaded: {'Yes' if os.environ.get('HF_TOKEN') else 'No'}\")\n",
    "\n",
    "# CRITICAL: Import unsloth FIRST for proper TRL patching\n",
    "import unsloth\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "import transformers\n",
    "import vllm\n",
    "import trl\n",
    "import torch\n",
    "\n",
    "print(f\"unsloth: {unsloth.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"vLLM: {vllm.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6629",
   "metadata": {},
   "source": [
    "## Ministral VL (Vision) Training Verification\n",
    "\n",
    "This section tests the complete vision model fine-tuning pipeline:\n",
    "- FastVisionModel loading\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3ba143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vision Training Pipeline Test ===",
      "==((====))==  Unsloth 2025.12.10: Fast Ministral3 patching. Transformers: 5.0.0rc1. vLLM: 0.14.0rc1.dev201+gadcf682fc.cu130.\n   \\\\   /|    NVIDIA GeForce RTX 4080 SUPER. Num GPUs = 1. Max memory: 15.568 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu130. CUDA: 8.9. CUDA Toolkit: 13.0. Triton: 3.5.1\n\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a36361cbf94b69962aee2f96e8e70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FastVisionModel loaded: Mistral3ForConditionalGeneration",
      "Unsloth: Making `model.base_model.model.model.vision_tower.transformer` require gradients",
      "âœ“ LoRA applied (33,751,040 trainable params)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset loaded (5 samples)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 5 | Num Epochs = 1 | Total steps = 2\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 2\n\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 2 x 1) = 2\n \"-____-\"     Trainable parameters = 33,751,040 of 3,882,841,088 (0.87% trained)"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 : < :, Epoch 0.40/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed (loss: 3.6458)",
      "âœ“ Inference test passed\nâœ“ Vision Training Pipeline test PASSED"
     ]
    }
   ],
   "source": [
    "# Complete Vision Pipeline Test (self-contained)\n",
    "# Tests: Model loading, LoRA, Dataset, Training (2 steps), Inference\n",
    "print(\"=== Vision Training Pipeline Test ===\")\n",
    "\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Load model\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Ministral-3-3B-Reasoning-2512\",\n",
    "    load_in_4bit=True,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    ")\n",
    "print(f\"âœ“ FastVisionModel loaded: {type(model).__name__}\")\n",
    "\n",
    "# 2. Apply LoRA\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    random_state=3407,\n",
    ")\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ“ LoRA applied ({trainable:,} trainable params)\")\n",
    "\n",
    "# 3. Load dataset\n",
    "dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train[:5]\")\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "converted_dataset = [convert_to_conversation(s) for s in dataset]\n",
    "print(f\"âœ“ Dataset loaded ({len(converted_dataset)} samples)\")\n",
    "\n",
    "# 4. Train (2 steps)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset=converted_dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        max_steps=2,\n",
    "        warmup_steps=0,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        fp16=not is_bf16_supported(),\n",
    "        bf16=is_bf16_supported(),\n",
    "        output_dir=\"outputs_ministral_vl_test\",\n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        max_seq_length=1024,\n",
    "    ),\n",
    ")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"âœ“ Training completed (loss: {trainer_stats.metrics.get('train_loss', 'N/A'):.4f})\")\n",
    "\n",
    "# 5. Inference test\n",
    "FastVisionModel.for_inference(model)\n",
    "test_image = dataset[0][\"image\"]\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}]}]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(test_image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=64, temperature=1.5, min_p=0.1)\n",
    "print(\"âœ“ Inference test passed\")\n",
    "print(\"âœ“ Vision Training Pipeline test PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a4288",
   "metadata": {},
   "source": [
    "## Test Complete\n",
    "\n",
    "The Vision Training Pipeline test has completed. The kernel will now shut down to release all GPU memory.\n",
    "\n",
    "### What Was Verified\n",
    "- FastVisionModel loading with 4-bit quantization\n",
    "- LoRA adapter application (vision + language layers)\n",
    "- Dataset loading and conversation formatting\n",
    "- SFTTrainer training loop (2 steps)\n",
    "- Post-training inference\n",
    "\n",
    "### Ready for Production\n",
    "If this test passed, your environment is ready for:\n",
    "- `Ministral_3_VL_(3B)_Vision.ipynb` - Full vision fine-tuning tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ea73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down kernel to release GPU memory..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shutdown kernel to release all GPU memory\n",
    "import IPython\n",
    "print(\"Shutting down kernel to release GPU memory...\")\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
