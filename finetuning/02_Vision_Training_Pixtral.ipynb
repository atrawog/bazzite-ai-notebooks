{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f100981d",
   "metadata": {},
   "source": [
    "# Unsloth Vision Training Verification (Pixtral)\n",
    "\n",
    "This notebook tests the complete vision model fine-tuning pipeline with Pixtral-12B:\n",
    "- FastVisionModel loading\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training\n",
    "\n",
    "**Model:** `unsloth/pixtral-12b-2409-bnb-4bit` (pre-quantized 4-bit)\n",
    "\n",
    "**Important:** This notebook includes a kernel shutdown cell at the end\n",
    "to release all GPU memory after the vision training test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a9845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HF_TOKEN loaded: Yes\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "/opt/pixi/.pixi/envs/default/lib/python3.13/site-packages/trl/__init__.py:203: UserWarning: TRL currently supports vLLM versions: 0.10.2, 0.11.0, 0.11.1, 0.11.2. You have version 0.14.0rc1.dev201+gadcf682fc.cu130 installed. We recommend installing a supported version to avoid compatibility issues.\n",
       "  if is_vllm_available():\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "unsloth: 2025.12.10\n",
       "transformers: 5.0.0rc1\n",
       "vLLM: 0.14.0rc1.dev201+gadcf682fc\n",
       "TRL: 0.26.2\n",
       "PyTorch: 2.9.1+cu130\n",
       "CUDA: True\n",
       "GPU: NVIDIA GeForce RTX 4080 SUPER\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment Setup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(f\"HF_TOKEN loaded: {'Yes' if os.environ.get('HF_TOKEN') else 'No'}\")\n",
    "\n",
    "# CRITICAL: Import unsloth FIRST for proper TRL patching\n",
    "import unsloth\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "import transformers\n",
    "import vllm\n",
    "import trl\n",
    "import torch\n",
    "\n",
    "print(f\"unsloth: {unsloth.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"vLLM: {vllm.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92908d",
   "metadata": {},
   "source": [
    "## Pixtral VL (Vision) Training Verification\n",
    "\n",
    "This section tests the complete vision model fine-tuning pipeline:\n",
    "- FastVisionModel loading (Pixtral-12B pre-quantized)\n",
    "- LoRA adapter configuration\n",
    "- Dataset loading and formatting\n",
    "- SFTTrainer training loop\n",
    "- Inference after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57235e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Vision Training Pipeline Test (Pixtral-12B) ===\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==((====))==  Unsloth 2025.12.10: Fast Llava patching. Transformers: 5.0.0rc1. vLLM: 0.14.0rc1.dev201+gadcf682fc.cu130.\n",
       "   \\\\   /|    NVIDIA GeForce RTX 4080 SUPER. Num GPUs = 1. Max memory: 15.568 GB. Platform: Linux.\n",
       "O^O/ \\_/ \\    Torch: 2.9.1+cu130. CUDA: 8.9. CUDA Toolkit: 13.0. Triton: 3.5.1\n",
       "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
       " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
       "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "The tied weights mapping and config for this model specifies to tie model.language_model.embed_tokens.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "The tokenizer you are loading from 'unsloth/pixtral-12b-2409-bnb-4bit' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "âœ“ FastVisionModel loaded: LlavaForConditionalGeneration\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Unsloth: Making `model.base_model.model.model.vision_tower.transformer` require gradients\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "âœ“ LoRA applied (66,060,288 trainable params)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "âœ“ Dataset loaded (5 samples)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
       "   \\\\   /|    Num examples = 5 | Num Epochs = 1 | Total steps = 2\n",
       "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 2\n",
       "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 2 x 1) = 2\n",
       " \"-____-\"     Trainable parameters = 66,060,288 of 12,748,800,000 (0.52% trained)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "âœ“ Training completed (loss: 3.2785)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "âœ“ Inference test passed\n",
       "âœ“ Vision Training Pipeline test PASSED\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete Vision Pipeline Test (self-contained)\n",
    "# Tests: Model loading, LoRA, Dataset, Training (2 steps), Inference\n",
    "print(\"=== Vision Training Pipeline Test (Pixtral-12B) ===\")\n",
    "\n",
    "from unsloth import FastVisionModel, is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Load model (pre-quantized 4-bit)\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/pixtral-12b-2409-bnb-4bit\",\n",
    "    load_in_4bit=True,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    ")\n",
    "print(f\"âœ“ FastVisionModel loaded: {type(model).__name__}\")\n",
    "\n",
    "# 2. Apply LoRA\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    random_state=3407,\n",
    ")\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ“ LoRA applied ({trainable:,} trainable params)\")\n",
    "\n",
    "# 3. Load dataset\n",
    "dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train[:5]\")\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "converted_dataset = [convert_to_conversation(s) for s in dataset]\n",
    "print(f\"âœ“ Dataset loaded ({len(converted_dataset)} samples)\")\n",
    "\n",
    "# 4. Train (2 steps)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset=converted_dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        max_steps=2,\n",
    "        warmup_steps=0,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        fp16=not is_bf16_supported(),\n",
    "        bf16=is_bf16_supported(),\n",
    "        output_dir=\"outputs_pixtral_vl_test\",\n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        max_seq_length=1024,\n",
    "    ),\n",
    ")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"âœ“ Training completed (loss: {trainer_stats.metrics.get('train_loss', 'N/A'):.4f})\")\n",
    "\n",
    "# 5. Inference test\n",
    "FastVisionModel.for_inference(model)\n",
    "test_image = dataset[0][\"image\"]\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}]}]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(test_image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=64, temperature=1.5, min_p=0.1)\n",
    "print(\"âœ“ Inference test passed\")\n",
    "print(\"âœ“ Vision Training Pipeline test PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af42f7",
   "metadata": {},
   "source": [
    "## Test Complete\n",
    "\n",
    "The Vision Training Pipeline test has completed. The kernel will now shut down to release all GPU memory.\n",
    "\n",
    "### What Was Verified\n",
    "- FastVisionModel loading with Pixtral-12B (pre-quantized 4-bit)\n",
    "- LoRA adapter application (vision + language layers)\n",
    "- Dataset loading and conversation formatting\n",
    "- SFTTrainer training loop (2 steps)\n",
    "- Post-training inference\n",
    "\n",
    "### Ready for Production\n",
    "If this test passed, your environment is ready for:\n",
    "- `03_SFT_Training_Pixtral_Vision.ipynb` - Full vision fine-tuning\n",
    "- `04_GRPO_Training_Pixtral_Vision.ipynb` - GRPO reinforcement learning\n",
    "- `07_RLOO_Training_Pixtral_Vision.ipynb` - RLOO reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690add37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down kernel to release GPU memory..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shutdown kernel to release all GPU memory\n",
    "import IPython\n",
    "print(\"Shutting down kernel to release GPU memory...\")\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
