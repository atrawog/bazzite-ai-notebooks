{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d6a5fa",
   "metadata": {},
   "source": [
    "# DPO Training Test: Qwen3-4B-Thinking-2507\n",
    "\n",
    "Tests Direct Preference Optimization (DPO) with Unsloth on Qwen3-4B-Thinking-2507.\n",
    "\n",
    "**Key features tested:**\n",
    "- FastLanguageModel loading with 4-bit quantization\n",
    "- LoRA adapter configuration\n",
    "- DPOTrainer with preference pairs that reward thinking quality\n",
    "- Chosen responses include self-questioning `<think>` blocks\n",
    "- Rejected responses have poor/no thinking\n",
    "\n",
    "**DPO Overview:**\n",
    "DPO learns from preference pairs (chosen vs rejected responses) without an explicit reward model. It directly optimizes the policy using the Bradley-Terry preference model.\n",
    "\n",
    "**Thinking Preference:**\n",
    "- **Chosen**: Responses with quality self-questioning reasoning in `<think>` blocks\n",
    "- **Rejected**: Responses with poor, minimal, or no thinking\n",
    "\n",
    "**Important:** This notebook includes a kernel shutdown cell at the end to release all GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f41e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "/opt/pixi/.pixi/envs/default/lib/python3.13/site-packages/trl/__init__.py:203: UserWarning: TRL currently supports vLLM versions: 0.10.2, 0.11.0, 0.11.1, 0.11.2. You have version 0.14.0rc1.dev201+gadcf682fc.cu130 installed. We recommend installing a supported version to avoid compatibility issues.\n",
       "  if is_vllm_available():\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Environment: unsloth 2025.12.10, PyTorch 2.9.1+cu130, NVIDIA GeForce RTX 4080 SUPER\n",
       "HF_TOKEN loaded: Yes\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# CRITICAL: Import unsloth FIRST for proper TRL patching\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel, is_bf16_supported\n",
    "\n",
    "import torch\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Environment summary\n",
    "gpu = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "print(f\"Environment: unsloth {unsloth.__version__}, PyTorch {torch.__version__}, {gpu}\")\n",
    "print(f\"HF_TOKEN loaded: {'Yes' if os.environ.get('HF_TOKEN') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb203e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Loading Qwen3-4B-Thinking-2507-unsloth-bnb-4bit...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==((====))==  Unsloth 2025.12.10: Fast Qwen3 patching. Transformers: 5.0.0.1. vLLM: 0.14.0rc1.dev201+gadcf682fc.cu130.\n",
       "   \\\\   /|    NVIDIA GeForce RTX 4080 SUPER. Num GPUs = 1. Max memory: 15.568 GB. Platform: Linux.\n",
       "O^O/ \\_/ \\    Torch: 2.9.1+cu130. CUDA: 8.9. CUDA Toolkit: 13.0. Triton: 3.5.1\n",
       "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
       " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
       "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Model loaded: Qwen3ForCausalLM\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Qwen3-4B-Thinking-2507 with 4-bit quantization\n",
    "MODEL_NAME = \"unsloth/Qwen3-4B-Thinking-2507-unsloth-bnb-4bit\"\n",
    "print(f\"\\nLoading {MODEL_NAME.split('/')[-1]}...\")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    max_seq_length=1024,  # Increased for thinking content\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "# Ensure pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"Model loaded: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33e1618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unsloth 2025.12.10 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LoRA applied: 33,030,144 trainable / 2,526,543,360 total (1.31%)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply LoRA adapters for DPO training\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"LoRA applied: {trainable:,} trainable / {total:,} total ({100*trainable/total:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4ccb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Dataset created: 5 preference pairs\n",
       "Chosen responses include <think> blocks with self-questioning\n",
       "Rejected responses have minimal/no reasoning\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create minimal synthetic preference dataset with thinking content (5 samples)\n",
    "# DPO requires: prompt, chosen response (with quality thinking), rejected response (poor/no thinking)\n",
    "\n",
    "preference_data = [\n",
    "    {\n",
    "        \"prompt\": \"Explain recursion in programming.\",\n",
    "        \"chosen\": \"<think>\\nWhat is recursion exactly? It's when a function calls itself. But why would you do that? To break down problems into smaller pieces. What's the key thing users need to understand? The base case - without it you get infinite loops.\\n</think>\\n\\nRecursion is when a function calls itself with a simpler version of the problem, including a base case to stop infinite loops.\",\n",
    "        \"rejected\": \"Recursion is just loops.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What is an API?\",\n",
    "        \"chosen\": \"<think>\\nHow do I explain API to someone? What does it stand for? Application Programming Interface. But what does that mean practically? It's like a contract between software systems. What's a good analogy? Like a waiter taking orders between you and the kitchen.\\n</think>\\n\\nAn API (Application Programming Interface) is a set of protocols that allows different software applications to communicate with each other.\",\n",
    "        \"rejected\": \"API is code.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Describe version control.\",\n",
    "        \"chosen\": \"<think>\\nWhat's the core purpose of version control? Tracking changes over time. Why is that useful? You can go back to previous versions, see who changed what. What systems exist? Git is the most popular. How should I frame this?\\n</think>\\n\\nVersion control is a system that records changes to files over time, allowing you to recall specific versions and collaborate with others.\",\n",
    "        \"rejected\": \"Version control saves files.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What is a database?\",\n",
    "        \"chosen\": \"<think>\\nWhat is the essential definition of a database? It stores data, but that's too simple. What makes it different from just files? It's organized and structured. What manages it? A DBMS. How do I make this clear?\\n</think>\\n\\nA database is an organized collection of structured data stored electronically, typically managed by a database management system (DBMS).\",\n",
    "        \"rejected\": \"A database stores stuff.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Explain object-oriented programming.\",\n",
    "        \"chosen\": \"<think>\\nWhat are the key concepts of OOP? Objects, classes, encapsulation, inheritance, polymorphism. But what's the core idea? Organizing code around objects that have both data and behavior. How do I explain this simply?\\n</think>\\n\\nObject-oriented programming (OOP) is a paradigm that organizes code into objects containing data (attributes) and behavior (methods).\",\n",
    "        \"rejected\": \"OOP uses objects.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Format for DPO\n",
    "def format_for_dpo(sample):\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": sample[\"prompt\"]}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": sample[\"chosen\"],\n",
    "        \"rejected\": sample[\"rejected\"],\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_list(preference_data)\n",
    "dataset = dataset.map(format_for_dpo)\n",
    "\n",
    "print(f\"Dataset created: {len(dataset)} preference pairs\")\n",
    "print(f\"Chosen responses include <think> blocks with self-questioning\")\n",
    "print(f\"Rejected responses have minimal/no reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f870e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[datasets.arrow_dataset|WARNING]num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Extracting prompt in train dataset (num_proc=5):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[datasets.arrow_dataset|WARNING]num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Applying chat template to train dataset (num_proc=5):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[datasets.arrow_dataset|WARNING]num_proc must be <= 5. Reducing num_proc to 5 for dataset of size 5.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train dataset (num_proc=5):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Starting DPO training with thinking preferences (2 steps)...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
       "   \\\\   /|    Num examples = 5 | Num Epochs = 1 | Total steps = 2\n",
       "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 1\n",
       "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 1 x 1) = 1\n",
       " \"-____-\"     Trainable parameters = 33,030,144 of 4,055,498,240 (0.81% trained)\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DPO training completed!\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DPO Training Configuration (minimal steps for testing)\n",
    "dpo_config = DPOConfig(\n",
    "    output_dir=\"outputs_dpo_qwen_think_test\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_steps=2,  # Minimal steps for testing\n",
    "    warmup_steps=0,\n",
    "    learning_rate=5e-6,  # Lower LR for DPO\n",
    "    logging_steps=1,\n",
    "    fp16=not is_bf16_supported(),\n",
    "    bf16=is_bf16_supported(),\n",
    "    optim=\"adamw_8bit\",\n",
    "    beta=0.1,  # DPO temperature\n",
    "    max_length=1024,  # Increased for thinking content\n",
    "    max_prompt_length=256,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Initialize DPO Trainer\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=dpo_config,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Starting DPO training with thinking preferences (2 steps)...\")\n",
    "trainer_stats = trainer.train()\n",
    "print(f\"DPO training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23453140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================\n",
       "DPO Training Pipeline Test (Thinking Mode)\n",
       "============================================================\n",
       "</think> token found: ‚úÖ YES\n",
       "Output tokens: 1024\n",
       "\n",
       "THINKING: Okay, the user is asking \"What is machine learning?\" Hmm, this seems like a beginner-level question. They might be completely new to the field, or maybe they've heard the term somewhere but don't understand it deeply. \n",
       "\n",
       "First, I should consider who this user could be. Could be a student, a curious p...\n",
       "\n",
       "RESPONSE: Machine learning (ML) is a **subset of artificial intelligence (AI)** where computer programs \"learn\" from data instead of being explicitly programmed for every single task. Instead of hardcoding rule...\n",
       "\n",
       "‚úÖ DPO Training Pipeline Test PASSED\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-training inference test\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_prompt = \"What is machine learning?\"\n",
    "messages = [{\"role\": \"user\", \"content\": test_prompt}]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,  # Increased to allow full thinking + response\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "# Get generated token IDs only (exclude prompt)\n",
    "input_length = inputs[\"input_ids\"].shape[1]\n",
    "generated_ids = outputs[0][input_length:].tolist()\n",
    "\n",
    "# Token-based parsing using </think> token ID\n",
    "THINK_END_TOKEN_ID = 151668\n",
    "\n",
    "if THINK_END_TOKEN_ID in generated_ids:\n",
    "    end_idx = generated_ids.index(THINK_END_TOKEN_ID)\n",
    "    thinking = tokenizer.decode(generated_ids[:end_idx], skip_special_tokens=True).strip()\n",
    "    final_resp = tokenizer.decode(generated_ids[end_idx + 1:], skip_special_tokens=True).strip()\n",
    "    think_tag_found = True\n",
    "else:\n",
    "    thinking = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "    final_resp = \"(Model did not complete thinking - increase max_new_tokens)\"\n",
    "    think_tag_found = False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DPO Training Pipeline Test (Thinking Mode)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"</think> token found: {'‚úÖ YES' if think_tag_found else '‚ùå NO'}\")\n",
    "print(f\"Output tokens: {len(generated_ids)}\")\n",
    "print(f\"\\nTHINKING: {thinking[:300]}...\" if len(thinking) > 300 else f\"\\nTHINKING: {thinking}\")\n",
    "print(f\"\\nRESPONSE: {final_resp[:200]}...\" if len(final_resp) > 200 else f\"\\nRESPONSE: {final_resp}\")\n",
    "\n",
    "if think_tag_found and thinking and final_resp:\n",
    "    print(\"\\n‚úÖ DPO Training Pipeline Test PASSED\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Test completed but output may need review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588490a7",
   "metadata": {},
   "source": [
    "## Test Complete\n",
    "\n",
    "The DPO Training Pipeline test with thinking preferences has completed successfully. The kernel will now shut down to release all GPU memory.\n",
    "\n",
    "### What Was Verified\n",
    "- FastLanguageModel loading with 4-bit quantization (Qwen3-4B-Thinking-2507)\n",
    "- LoRA adapter configuration for preference learning\n",
    "- Preference dataset with thinking quality contrast (chosen vs rejected)\n",
    "- DPOTrainer training loop (2 steps)\n",
    "- Post-training inference with thinking output\n",
    "\n",
    "### DPO Concepts with Thinking\n",
    "- **Thinking Preference**: Chosen responses have quality self-questioning `<think>` blocks\n",
    "- **Contrast Learning**: Rejected responses have poor/no reasoning\n",
    "- **Beta Parameter**: Controls strength of preference signal\n",
    "\n",
    "### Ready for Production\n",
    "If this test passed, your environment is ready for:\n",
    "- DPO training with real preference data including thinking quality\n",
    "- Human preference alignment for chain-of-thought reasoning\n",
    "- Post-SFT thinking preference optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686a28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shutting down kernel to release GPU memory...\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shutdown kernel to release all GPU memory\n",
    "import IPython\n",
    "print(\"Shutting down kernel to release GPU memory...\")\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
