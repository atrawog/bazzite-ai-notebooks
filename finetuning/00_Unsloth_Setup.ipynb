{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5f2f39",
   "metadata": {},
   "source": [
    "# Unsloth Environment Verification\n",
    "\n",
    "This notebook verifies that all components are correctly installed for running Unsloth notebooks:\n",
    "- GRPO (Reinforcement Learning)\n",
    "- Vision fine-tuning (Ministral VL)\n",
    "- fast_inference support\n",
    "\n",
    "**Run this after rebuilding the jupyter pod to verify the environment.**\n",
    "\n",
    "**Note:** This notebook does NOT use vLLM fast_inference. For fast_inference tests, see:\n",
    "- `01_FastInference_Llama.ipynb` - Llama-3.2-1B\n",
    "- `02_FastInference_Qwen.ipynb` - Qwen3-4B\n",
    "- `03_FastInference_Ministral.ipynb` - Ministral models\n",
    "- `04_Vision_Training.ipynb` - Vision training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env from notebook directory\n",
    "load_dotenv()\n",
    "print(f\"✓ HF_TOKEN loaded: {'Yes' if os.environ.get('HF_TOKEN') else 'No'}\")\n",
    "\n",
    "# CRITICAL: Import unsloth FIRST for proper TRL patching\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel, FastVisionModel\n",
    "print(f\"✓ unsloth: {unsloth.__version__}\")\n",
    "\n",
    "import transformers\n",
    "print(f\"✓ transformers: {transformers.__version__}\")\n",
    "\n",
    "import vllm\n",
    "print(f\"✓ vLLM: {vllm.__version__}\")\n",
    "\n",
    "import trl\n",
    "print(f\"✓ TRL: {trl.__version__}\")\n",
    "\n",
    "import torch\n",
    "print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports for Reinforcement Learning notebook\n",
    "print(\"=== GRPO/RL Imports ===\")\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from datasets import Dataset\n",
    "print(\"✓ All GRPO imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports for Vision notebook\n",
    "print(\"=== Vision/SFT Imports ===\")\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from unsloth import is_bf16_supported\n",
    "from transformers import TextStreamer\n",
    "print(\"✓ All Vision imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading with FastLanguageModel (standard inference, no vLLM)\n",
    "print(\"=== Testing Model Loading ===\")\n",
    "model, tokenizer = None, None\n",
    "try:\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        \"unsloth/Ministral-3-3B-Reasoning-2512-bnb-4bit\",\n",
    "        max_seq_length=2048,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    print(f\"✓ Model loaded: {type(model).__name__}\")\n",
    "    print(f\"✓ Tokenizer: {type(tokenizer).__name__}\")\n",
    "    print(\"✓ FastLanguageModel test PASSED\")\n",
    "finally:\n",
    "    del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fast_inference capability\n",
    "print(\"=== Fast Inference Check ===\")\n",
    "print(\"fast_inference=True uses vLLM as backend for 2x faster inference\")\n",
    "print(f\"vLLM version: {vllm.__version__}\")\n",
    "print(f\"Unsloth version: {unsloth.__version__}\")\n",
    "\n",
    "# Check if fast_inference is supported\n",
    "import inspect\n",
    "sig = inspect.signature(FastLanguageModel.from_pretrained)\n",
    "if 'fast_inference' in sig.parameters:\n",
    "    print(\"✓ fast_inference parameter available\")\n",
    "else:\n",
    "    print(\"⚠ fast_inference parameter not found\")\n",
    "\n",
    "# Check FastVisionModel\n",
    "sig_vision = inspect.signature(FastVisionModel.from_pretrained)\n",
    "has_fast_inference_vision = 'fast_inference' in sig_vision.parameters\n",
    "print(f\"✓ fast_inference in FastVisionModel: {has_fast_inference_vision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b643373-ae86-4827-9534-cf29efcfc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown kernel to release all GPU memory\n",
    "import IPython\n",
    "print(\"Shutting down kernel to release GPU memory...\")\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b4f2e",
   "metadata": {},
   "source": [
    "## Verification Summary\n",
    "\n",
    "If all cells above ran without errors, your environment is ready for:\n",
    "\n",
    "1. **Reinforcement Learning** (GRPO/TRL imports verified)\n",
    "2. **Vision Fine-tuning** (SFT imports verified)\n",
    "3. **fast_inference** (parameter available)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Run the specialized fast_inference notebooks (each requires fresh kernel):\n",
    "- `01_FastInference_Llama.ipynb` - Llama-3.2-1B with vLLM\n",
    "- `02_FastInference_Qwen.ipynb` - Qwen3-4B with vLLM\n",
    "- `03_FastInference_Ministral.ipynb` - Ministral models\n",
    "- `04_Vision_Training.ipynb` - Complete vision training pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
