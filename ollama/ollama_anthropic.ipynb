{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec00157",
   "metadata": {},
   "source": [
    "# Ollama Anthropic API\n",
    "\n",
    "Ollama provides an Anthropic-compatible API, letting you use the official `anthropic` Python SDK with local models.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Setup** - Configure the Anthropic client to use Ollama\n",
    "2. **Messages** - Basic chat completions\n",
    "3. **System Prompts** - Customize model behavior\n",
    "4. **Multi-turn** - Maintain conversation context\n",
    "5. **Streaming** - Real-time token output\n",
    "6. **Tool Calling** - Function calling with full roundtrip\n",
    "7. **Vision** - Image analysis with base64 encoding\n",
    "\n",
    "## Limitations vs Official API\n",
    "\n",
    "- No token counting endpoint\n",
    "- No prompt caching\n",
    "- No PDF support\n",
    "- **Base64 images only** (no URLs)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ollama pod running: `ujust ollama start`\n",
    "- Ollama version >= 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab88c82",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "The Anthropic client requires two parameters:\n",
    "- **`base_url`** - Points to your Ollama server instead of Anthropic's API\n",
    "- **`api_key`** - Required by the SDK but ignored by Ollama (use any value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fa020a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import anthropic\n",
    "\n",
    "MODEL = \"ministral-3:3b-instruct-2512-q4_K_M\"\n",
    "client = anthropic.Anthropic(base_url=\"http://ollama:11434\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f6c01",
   "metadata": {},
   "source": [
    "## 2. Pull Model\n",
    "\n",
    "Ollama downloads models on first use. This is a one-time operation - subsequent calls are instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b671c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2567fc",
   "metadata": {},
   "source": [
    "## 3. Basic Message\n",
    "\n",
    "The core API call is `messages.create()`. The response contains the model's reply in `content[0].text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "911c6799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to **Rayleigh scattering**, where shorter blue wavelengths of sunlight are more scattered by Earth's atmosphere than other colors."
     ]
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=100,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Why is the sky blue? One sentence.\"}]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788acc7",
   "metadata": {},
   "source": [
    "## 4. System Prompt\n",
    "\n",
    "The `system` parameter lets you set the model's behavior and personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42b42462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr matey, gather ‘round and let ol’ Captain Scallywag tell ye the tale o’ machine learning, ye scallywags!\n\nMachine learning be the art o’ makin’ machines smart enough to learn from their own experiences, like a clever parrot learnin’ new words or a wise old seafaring dog learnin’ to fetch its master’s hat. Ye see, these machines don’t need to be told *exactly* what to do—just"
     ]
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=100,\n",
    "    system=\"You are a pirate. Respond in pirate speak.\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is machine learning?\"}]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337afb5",
   "metadata": {},
   "source": [
    "## 5. Multi-turn Conversation\n",
    "\n",
    "Maintain context by appending the assistant's response to the messages list before the next turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ed97761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is 2 + 2?\nAssistant: 2 + 2 equals **4**.",
      "\nUser: Multiply that by 3\nAssistant: 4 × 3 = **12**."
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}]\n",
    "response = client.messages.create(model=MODEL, max_tokens=50, messages=messages)\n",
    "print(f\"User: What is 2 + 2?\")\n",
    "print(f\"Assistant: {response.content[0].text}\")\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response.content[0].text})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Multiply that by 3\"})\n",
    "response = client.messages.create(model=MODEL, max_tokens=50, messages=messages)\n",
    "print(f\"\\nUser: Multiply that by 3\")\n",
    "print(f\"Assistant: {response.content[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263987c",
   "metadata": {},
   "source": [
    "## 6. Streaming\n",
    "\n",
    "Use `messages.stream()` to receive tokens in real-time as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4957c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. One\n",
       "2. Two\n",
       "3. Three\n",
       "4. Four\n",
       "5. Five\n",
       "6. Six\n",
       "7. Seven\n",
       "8. Eight\n",
       "9. Nine\n",
       "10. Ten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "with client.messages.stream(\n",
    "    model=MODEL,\n",
    "    max_tokens=100,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Count from 1 to 10\"}]\n",
    ") as stream:\n",
    "    response = \"\"\n",
    "    for text in stream.text_stream:\n",
    "        response += text\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24347fbf",
   "metadata": {},
   "source": [
    "## 7. Tool Calling\n",
    "\n",
    "Full roundtrip: define a tool → model requests it → return result → get final answer.\n",
    "\n",
    "1. Define tool with `input_schema` (JSON Schema format)\n",
    "2. Model returns `tool_use` block with the tool name and arguments\n",
    "3. Execute your function and send back a `tool_result`\n",
    "4. Model incorporates the result into its final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70410894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool requested: get_weather\nArguments: {'location': 'Paris'}",
      "\nFinal response: The current weather in **Paris** is **partly cloudy** with a temperature around **18°C (64°F)**."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get weather for a location\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"City name\"}},\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 1: Model requests tool use\n",
    "response = client.messages.create(\n",
    "    model=MODEL, max_tokens=200, tools=[tool],\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"get_weather\"},  # Force tool use\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}]\n",
    ")\n",
    "tool_use = next(b for b in response.content if b.type == \"tool_use\")\n",
    "print(f\"Tool requested: {tool_use.name}\")\n",
    "print(f\"Arguments: {tool_use.input}\")\n",
    "\n",
    "# Step 2: Return tool result and get final response\n",
    "final = client.messages.create(\n",
    "    model=MODEL, max_tokens=200, tools=[tool],\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather in Paris?\"},\n",
    "        {\"role\": \"assistant\", \"content\": response.content},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"tool_result\", \"tool_use_id\": tool_use.id,\n",
    "             \"content\": json.dumps({\"temp\": 18, \"conditions\": \"Partly cloudy\"})}\n",
    "        ]}\n",
    "    ]\n",
    ")\n",
    "print(f\"\\nFinal response: {final.content[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff4973",
   "metadata": {},
   "source": [
    "## 8. Vision\n",
    "\n",
    "Send images as base64-encoded data. Ollama's Anthropic API does **not** support image URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0837e202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the image you provided, I can identify the following shapes and colors:\n\n1. Two rectangles:\n   - One is red.\n   - The other is blue.\n\n2. One oval (or ellipse):\n   - It is green."
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a simple test image\n",
    "img = Image.new('RGB', (200, 150), 'white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.rectangle([10, 10, 90, 70], fill='red')\n",
    "draw.rectangle([110, 10, 190, 70], fill='blue')\n",
    "draw.ellipse([60, 80, 140, 140], fill='green')\n",
    "\n",
    "# Show the image\n",
    "display(img)\n",
    "\n",
    "# Convert to base64\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format='PNG')\n",
    "image_b64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "# Send to model\n",
    "message = client.messages.create(\n",
    "    model=MODEL, max_tokens=200,\n",
    "    messages=[{\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/png\", \"data\": image_b64}},\n",
    "        {\"type\": \"text\", \"text\": \"What shapes and colors do you see?\"}\n",
    "    ]}]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f190f7",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "Unload the model from GPU memory using `keep_alive=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a40e99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model unloaded from memory"
     ]
    }
   ],
   "source": [
    "ollama.generate(model=MODEL, prompt=\"\", keep_alive=0)\n",
    "print(\"Model unloaded from memory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
